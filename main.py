# === ImportaciÃ³n de librerÃ­as ===
import streamlit as st                           # Interfaz web interactiva
import cv2                                       # Procesamiento de imÃ¡genes con OpenCV
import numpy as np                               # CÃ¡lculos numÃ©ricos
import time                                      # MediciÃ³n de tiempo
from collections import deque                    # Estructura para guardar historial de atenciÃ³n
import mediapipe as mp                           # LibrerÃ­a de visiÃ³n por computadora en tiempo real

# === ImportaciÃ³n de mÃ³dulos personalizados ===
from detector import evaluar_atencion, dibujar_landmarks
from segmentacion import detectar_presencia_persona, aplicar_mascara_segmentacion
from graficos import graficar_atencion

# ---------- Estado inicial ----------
# InicializaciÃ³n de variables persistentes entre ciclos (usando session_state)
if "running" not in st.session_state:
    st.session_state.running = False              # Indica si estÃ¡ en modo monitoreo
    st.session_state.cap = None                   # CÃ¡mara de video
    st.session_state.face_mesh = None             # Modelo de detecciÃ³n facial
    st.session_state.segmentador = None           # Modelo de segmentaciÃ³n semÃ¡ntica
    st.session_state.ventana_atencion = deque(maxlen=100)   # Buffer con Ãºltimos niveles de atenciÃ³n
    st.session_state.x_vals = deque(maxlen=100)             # Buffer con los nÃºmeros de frame
    st.session_state.total_frames = 0             # Conteo de todos los frames procesados
    st.session_state.atencion_frames = 0          # Conteo de frames con atenciÃ³n detectada
    st.session_state.start_time = None            # Tiempo de inicio del monitoreo
    st.session_state.last_report_time = 0         # Ãšltimo timestamp en que se actualizÃ³ el sidebar
    st.session_state.attention_log = []           # Historial completo del Ã­ndice de atenciÃ³n


# ---------- UI ----------
st.title("ðŸŽ¯ Monitor de AtenciÃ³n Visual en Tiempo Real")
st.markdown("""
Este programa utiliza visiÃ³n por computadora para analizar tu nivel de atenciÃ³n durante una videollamada.
EvalÃºa si tu rostro estÃ¡ centrado y si tu mirada se mantiene hacia el frente.  
Ideal para contextos educativos, de trabajo remoto o validaciÃ³n de presencia.

ðŸ‘ï¸â€ðŸ—¨ï¸ A travÃ©s de la webcam, el sistema detecta si desviÃ¡s la mirada, girÃ¡s la cabeza o bajÃ¡s la vista, y muestra un indicador visual de atenciÃ³n junto a un grÃ¡fico en tiempo real.
### Instrucciones:
1. Asegurate de que tu cÃ¡mara estÃ© encendida y funcionando.
2. AjustÃ¡ los umbrales de atenciÃ³n en la barra lateral segÃºn tu preferencia (lo ideal es dejarlo en 0.4 para giro a la izquierda, 0.6 para giro a la derecha y 0.25 para cabeza baja).
3. PresionÃ¡ "Iniciar monitoreo" para comenzar a evaluar tu atenciÃ³n.
4. ObservÃ¡ el indicador de atenciÃ³n y el grÃ¡fico en tiempo real.
5. Detenelo cuando quieras y revisÃ¡ el resumen de tu atenciÃ³n.            
""")
st.subheader("ðŸ‘‰ La premisa es la siguiente ðŸ‘ˆ")
st.markdown("Para demostrar tu atenciÃ³n, procurÃ¡ estar justo en medio de donde te muestra la cÃ¡mara ðŸ˜‰")

########### SIDEBAR ###########
with st.sidebar:
    st.subheader("ðŸ¤“ Umbrales de AtenciÃ³n")
    
    # Ajuste de umbrales para evaluar quÃ© se considera â€œatenciÃ³nâ€
    with st.expander("ðŸŽ› Ajustes de Umbrales", expanded=False):
        st.markdown("""
        AjustÃ¡ la sensibilidad del sistema de atenciÃ³n:
        - **Giro izquierda/derecha**: margen de movimiento horizontal permitido.
        - **Cabeza baja**: inclinaciÃ³n vertical antes de penalizar.
        """)
        umbral_giro_izquierda = st.slider("Giro hacia izquierda", 0.0, 1.0, 0.4, step=0.01)
        umbral_giro_derecha   = st.slider("Giro hacia derecha",  0.0, 1.0, 0.6, step=0.01)
        umbral_ojos_y_baja    = st.slider("Cabeza baja",          0.0, 1.0, 0.25, step=0.01)

    st.markdown("---")
    st.subheader("âš™ï¸ ConfiguraciÃ³n")

    # Opciones de visualizaciÃ³n
    # OpciÃ³n 1: Mostrar landmarks faciales
    mostrar_landmarks = st.checkbox("ðŸ˜€ Mostrar landmarks faciales", value=True)
    st.caption("Visualiza los puntos y lÃ­neas sobre tu rostro (FaceMesh).")

    # OpciÃ³n 2: Activar segmentaciÃ³n semÃ¡ntica
    usar_segmentacion = st.checkbox("ðŸ–¼ Activar segmentaciÃ³n semÃ¡ntica", value=True)
    st.caption("Valida que haya una persona real (no una imagen). Requiere cÃ¡mara activa.")

    # OpciÃ³n 3: Ver mÃ¡scara de segmentaciÃ³n
    ver_mascara_segmentacion = st.checkbox("ðŸ‘½ Ver mÃ¡scara de segmentaciÃ³n", value=True)
    st.caption("Superpone una mÃ¡scara verde sobre la persona detectada en la imagen. La idea es separar figura de fondo")

    # OpciÃ³n 4: Mostrar resumen de atenciÃ³n
    mostrar_tabla = st.checkbox("ðŸ“Š Mostrar resumen de atenciÃ³n al finalizar", value=True)
    st.caption("Muestra un grÃ¡fico y el promedio de atenciÃ³n al detener el monitoreo.")

    # CronÃ³metro de tiempo activo
    if st.session_state.start_time:
        elapsed = int(time.time() - st.session_state.start_time)
        minutes, seconds = divmod(elapsed, 60)
        st.markdown(f"â±ï¸ Tiempo de llamada: **{minutes:02d}:{seconds:02d}**")

# ---------- Botones ----------
# BotÃ³n para iniciar monitoreo
if not st.session_state.running:
    if st.button("â–¶ï¸ Iniciar monitoreo"):
        st.session_state.running = True
        st.session_state.start_time = time.time()
        st.session_state.total_frames = 0
        st.session_state.atencion_frames = 0
        st.session_state.attention_log.clear()
        st.session_state.ventana_atencion.clear()
        st.session_state.x_vals.clear()
else:
    # BotÃ³n para detener monitoreo y liberar la cÃ¡mara
    if st.button("ðŸ›‘ Detener monitoreo"):
        st.session_state.running = False
        if st.session_state.cap:
            st.session_state.cap.release()
            st.session_state.cap = None

# ---------- Procesamiento ----------
if st.session_state.running:

    if st.session_state.cap is None:
        with st.spinner("âŒ› Cargando modelo y preparando la cÃ¡mara: va a tomar un minuto"):
            st.session_state.cap = cv2.VideoCapture(0)
            st.session_state.face_mesh = mp.solutions.face_mesh.FaceMesh(
            max_num_faces=1, refine_landmarks=True,
            min_detection_confidence=0.5, min_tracking_confidence=0.5
        )
        st.session_state.segmentador = mp.solutions.selfie_segmentation.SelfieSegmentation(model_selection=1)

    col1, col2 = st.columns(2)
    video_placeholder = col1.empty()
    grafico_placeholder = col2.empty()

    while st.session_state.running:
        ret, frame = st.session_state.cap.read()
        if not ret:
            break

        # Procesamiento bÃ¡sico de frame
        frame = cv2.flip(frame, 1)                           # Espejo horizontal (efecto selfie)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)         # ConversiÃ³n a RGB para MediaPipe
        results = st.session_state.face_mesh.process(rgb)    # DetecciÃ³n de rostro
        segment = st.session_state.segmentador.process(rgb)  # SegmentaciÃ³n de persona
        h, w, _ = frame.shape

        # Contador de frames
        st.session_state.total_frames += 1
        score = 0
        hay_persona = True

        # ValidaciÃ³n de persona real (evita fotos)
        if usar_segmentacion:
            hay_persona = detectar_presencia_persona(segment.segmentation_mask)

        # Si se detecta rostro y persona vÃ¡lida...
        if hay_persona and results.multi_face_landmarks:
            for rostro in results.multi_face_landmarks:
                if mostrar_landmarks:
                    frame = dibujar_landmarks(frame, rostro)
                score, _ = evaluar_atencion(
                    rostro, w, h,
                    umbral_giro_izquierda, umbral_giro_derecha, umbral_ojos_y_baja
                )

            # ClasificaciÃ³n visual segÃºn atenciÃ³n
            if score >= 0.7:
                st.session_state.atencion_frames += 1
                texto = "ATENTO"
                color = (0, 255, 0)
            else:
                texto = "NO ATENTO"
                color = (0, 0, 255)
        else:
            texto = "Sin rostro o sin persona"
            color = (150, 150, 255)

        # CÃ¡lculo del Ã­ndice de atenciÃ³n y actualizaciÃ³n de buffers
        atencion_index = int((st.session_state.atencion_frames / st.session_state.total_frames) * 100)
        st.session_state.ventana_atencion.append(atencion_index)
        st.session_state.x_vals.append(st.session_state.total_frames)
        st.session_state.attention_log.append(atencion_index)

        # Anotaciones visuales en el frame
        cv2.putText(frame, texto, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)
        cv2.putText(frame, f"AtenciÃ³n: {atencion_index}%", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        # AplicaciÃ³n de mÃ¡scara de segmentaciÃ³n si estÃ¡ activada
        if ver_mascara_segmentacion and usar_segmentacion:
            frame = aplicar_mascara_segmentacion(frame, segment.segmentation_mask)

        # Mostrar frame y grÃ¡fico
        video_placeholder.image(frame, channels="BGR")
        fig = graficar_atencion(st.session_state.ventana_atencion, st.session_state.x_vals)
        grafico_placeholder.pyplot(fig)

        # ActualizaciÃ³n lateral del promedio cada 30 segundos
        elapsed = int(time.time() - st.session_state.start_time)
        if elapsed - st.session_state.last_report_time >= 30:
            ultimos_30 = st.session_state.attention_log[-30:]
            if ultimos_30:
                promedio = sum(ultimos_30) / len(ultimos_30)
                st.sidebar.info(f"ðŸ§  AtenciÃ³n Ãºltimos 30s: **{promedio:.1f}%**")
            st.session_state.last_report_time = elapsed

        time.sleep(0.03)  # Espera corta para no saturar CPU


# ---------- Resumen final ----------
# Muestra grÃ¡fico final y promedio cuando se detiene el monitoreo
if not st.session_state.running and st.session_state.attention_log and mostrar_tabla:
    st.subheader("ðŸ“‹ Resumen de atenciÃ³n")
    promedio_total = sum(st.session_state.attention_log) / len(st.session_state.attention_log)
    st.markdown(f"ðŸ§  Promedio total: **{promedio_total:.2f}%**")
    fig_final = graficar_atencion(st.session_state.ventana_atencion, st.session_state.x_vals)
    st.pyplot(fig_final)

# ---------- Footer fijo ----------
st.markdown(
    """
    <style>
        .footer {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            background-color: #f9f9f9;
            color: #666;
            text-align: center;
            font-size: 0.85em;
            padding: 0.5em 0;
            border-top: 1px solid #ddd;
        }
    </style>
    <div class="footer">
        Desarrollado por <strong>NicolÃ¡s Bargioni</strong> | AÃ±o 2025 | ISSD: Inteligencia Artificial y Ciencia de Datos ðŸ§ 
    </div>
    """,
    unsafe_allow_html=True
)