# === Importaci√≥n de librer√≠as ===
import streamlit as st                           # Interfaz web interactiva
import cv2                                       # Procesamiento de im√°genes con OpenCV
import numpy as np                               # C√°lculos num√©ricos
import time                                      # Medici√≥n de tiempo
from collections import deque                    # Estructura para guardar historial de atenci√≥n
import mediapipe as mp                           # Librer√≠a de visi√≥n por computadora en tiempo real

# === Importaci√≥n de m√≥dulos personalizados ===
from detector import evaluar_atencion, dibujar_landmarks
from segmentacion import detectar_presencia_persona, aplicar_mascara_segmentacion
from graficos import graficar_atencion

# ---------- Estado inicial ----------
# Inicializaci√≥n de variables persistentes entre ciclos (usando session_state)
if "running" not in st.session_state:
    st.session_state.running = False              # Indica si est√° en modo monitoreo
    st.session_state.cap = None                   # C√°mara de video
    st.session_state.face_mesh = None             # Modelo de detecci√≥n facial
    st.session_state.segmentador = None           # Modelo de segmentaci√≥n sem√°ntica
    st.session_state.ventana_atencion = deque(maxlen=100)   # Buffer con √∫ltimos niveles de atenci√≥n
    st.session_state.x_vals = deque(maxlen=100)             # Buffer con los n√∫meros de frame
    st.session_state.total_frames = 0             # Conteo de todos los frames procesados
    st.session_state.atencion_frames = 0          # Conteo de frames con atenci√≥n detectada
    st.session_state.start_time = None            # Tiempo de inicio del monitoreo
    st.session_state.last_report_time = 0         # √öltimo timestamp en que se actualiz√≥ el sidebar
    st.session_state.attention_log = []           # Historial completo del √≠ndice de atenci√≥n


# ---------- UI ----------
st.title("üéØ Monitor de Atenci√≥n Visual en Tiempo Real")
st.markdown("""
Este programa utiliza visi√≥n por computadora para analizar tu nivel de atenci√≥n durante una videollamada.
Eval√∫a si tu rostro est√° centrado y si tu mirada se mantiene hacia el frente.  
Ideal para contextos educativos, de trabajo remoto o validaci√≥n de presencia.

üëÅÔ∏è‚Äçüó®Ô∏è A trav√©s de la webcam, el sistema detecta si desvi√°s la mirada, gir√°s la cabeza o baj√°s la vista, y muestra un indicador visual de atenci√≥n junto a un gr√°fico en tiempo real.
### Instrucciones:
1. Asegurate de que tu c√°mara est√© encendida y funcionando.
2. Ajust√° los umbrales de atenci√≥n en la barra lateral seg√∫n tu preferencia (lo ideal es dejarlo en 0.4 para giro a la izquierda, 0.6 para giro a la derecha y 0.25 para cabeza baja).
3. Presion√° "Iniciar monitoreo" para comenzar a evaluar tu atenci√≥n.
4. Observ√° el indicador de atenci√≥n y el gr√°fico en tiempo real.
5. Detenelo cuando quieras y revis√° el resumen de tu atenci√≥n.            
""")
st.subheader("üëâ La premisa es la siguiente üëà")
st.markdown("Para demostrar tu atenci√≥n, procur√° estar justo en medio de donde te muestra la c√°mara üòâ")

########### SIDEBAR ###########
with st.sidebar:
    st.subheader("ü§ì Umbrales de Atenci√≥n")
    
    # Ajuste de umbrales para evaluar qu√© se considera ‚Äúatenci√≥n‚Äù
    with st.expander("üéõ Ajustes de Umbrales", expanded=False):
        st.markdown("""
        Ajust√° la sensibilidad del sistema de atenci√≥n:
        - **Giro izquierda/derecha**: margen de movimiento horizontal permitido.
        - **Cabeza baja**: inclinaci√≥n vertical antes de penalizar.
        """)
        umbral_giro_izquierda = st.slider("Giro hacia izquierda", 0.0, 1.0, 0.4, step=0.01)
        umbral_giro_derecha   = st.slider("Giro hacia derecha",  0.0, 1.0, 0.6, step=0.01)
        umbral_ojos_y_baja    = st.slider("Cabeza baja",          0.0, 1.0, 0.25, step=0.01)

    st.markdown("---")
    st.subheader("‚öôÔ∏è Configuraci√≥n")

    # Opciones de visualizaci√≥n
    # Opci√≥n 1: Mostrar landmarks faciales
    mostrar_landmarks = st.checkbox("üòÄ Mostrar landmarks faciales", value=True)
    st.caption("Visualiza los puntos y l√≠neas sobre tu rostro (FaceMesh).")

    # Opci√≥n 2: Activar segmentaci√≥n sem√°ntica
    usar_segmentacion = st.checkbox("üñº Activar segmentaci√≥n sem√°ntica", value=True)
    st.caption("Valida que haya una persona real (no una imagen). Requiere c√°mara activa.")

    # Opci√≥n 3: Ver m√°scara de segmentaci√≥n
    ver_mascara_segmentacion = st.checkbox("üëΩ Ver m√°scara de segmentaci√≥n", value=True)
    st.caption("Superpone una m√°scara verde sobre la persona detectada en la imagen. La idea es separar figura de fondo")

    # Opci√≥n 4: Mostrar resumen de atenci√≥n
    mostrar_tabla = st.checkbox("üìä Mostrar resumen de atenci√≥n al finalizar", value=True)
    st.caption("Muestra un gr√°fico y el promedio de atenci√≥n al detener el monitoreo.")

    # Cron√≥metro de tiempo activo
    if st.session_state.start_time:
        elapsed = int(time.time() - st.session_state.start_time)
        minutes, seconds = divmod(elapsed, 60)
        st.markdown(f"‚è±Ô∏è Tiempo de llamada: **{minutes:02d}:{seconds:02d}**")

# ---------- Botones ----------
# Bot√≥n para iniciar monitoreo
if not st.session_state.running:
    if st.button("‚ñ∂Ô∏è Iniciar monitoreo"):
        st.session_state.running = True
        st.session_state.start_time = time.time()
        st.session_state.total_frames = 0
        st.session_state.atencion_frames = 0
        st.session_state.attention_log.clear()
        st.session_state.ventana_atencion.clear()
        st.session_state.x_vals.clear()
else:
    # Bot√≥n para detener monitoreo y liberar la c√°mara
    if st.button("üõë Detener monitoreo"):
        st.session_state.running = False
        if st.session_state.cap:
            st.session_state.cap.release()
            st.session_state.cap = None

# ---------- Procesamiento ----------
if st.session_state.running:

    if st.session_state.cap is None:
        with st.spinner("‚åõ Cargando modelo y preparando la c√°mara: va a tomar un minuto"):
            st.session_state.cap = cv2.VideoCapture(0)
            st.session_state.face_mesh = mp.solutions.face_mesh.FaceMesh(
            max_num_faces=1, refine_landmarks=True,
            min_detection_confidence=0.5, min_tracking_confidence=0.5
        )
        st.session_state.segmentador = mp.solutions.selfie_segmentation.SelfieSegmentation(model_selection=1)

    col1, col2 = st.columns(2)
    video_placeholder = col1.empty()
    grafico_placeholder = col2.empty()

    while st.session_state.running:
        ret, frame = st.session_state.cap.read()
        if not ret:
            break

        # Procesamiento b√°sico de frame
        frame = cv2.flip(frame, 1)                           # Espejo horizontal (efecto selfie)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)         # Conversi√≥n a RGB para MediaPipe
        results = st.session_state.face_mesh.process(rgb)    # Detecci√≥n de rostro
        segment = st.session_state.segmentador.process(rgb)  # Segmentaci√≥n de persona
        h, w, _ = frame.shape

        # Contador de frames
        st.session_state.total_frames += 1
        score = 0
        hay_persona = True

        # Validaci√≥n de persona real (evita fotos)
        if usar_segmentacion:
            hay_persona = detectar_presencia_persona(segment.segmentation_mask)

        # Si se detecta rostro y persona v√°lida...
        if hay_persona and results.multi_face_landmarks:
            for rostro in results.multi_face_landmarks:
                if mostrar_landmarks:
                    frame = dibujar_landmarks(frame, rostro)
                score, _ = evaluar_atencion(
                    rostro, w, h,
                    umbral_giro_izquierda, umbral_giro_derecha, umbral_ojos_y_baja
                )

            # Clasificaci√≥n visual seg√∫n atenci√≥n
            if score >= 0.7:
                st.session_state.atencion_frames += 1
                texto = "ATENTO"
                color = (0, 255, 0)
            else:
                texto = "NO ATENTO"
                color = (0, 0, 255)
        else:
            texto = "Sin rostro o sin persona"
            color = (150, 150, 255)

        # C√°lculo del √≠ndice de atenci√≥n y actualizaci√≥n de buffers
        atencion_index = int((st.session_state.atencion_frames / st.session_state.total_frames) * 100)
        st.session_state.ventana_atencion.append(atencion_index)
        st.session_state.x_vals.append(st.session_state.total_frames)
        st.session_state.attention_log.append(atencion_index)

        # Anotaciones visuales en el frame
        cv2.putText(frame, texto, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)
        cv2.putText(frame, f"Atenci√≥n: {atencion_index}%", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        # Aplicaci√≥n de m√°scara de segmentaci√≥n si est√° activada
        if ver_mascara_segmentacion and usar_segmentacion:
            frame = aplicar_mascara_segmentacion(frame, segment.segmentation_mask)

        # Mostrar frame y gr√°fico
        video_placeholder.image(frame, channels="BGR")
        fig = graficar_atencion(st.session_state.ventana_atencion, st.session_state.x_vals)
        grafico_placeholder.pyplot(fig)

        # Actualizaci√≥n lateral del promedio cada 30 segundos
        elapsed = int(time.time() - st.session_state.start_time)
        if elapsed - st.session_state.last_report_time >= 30:
            ultimos_30 = st.session_state.attention_log[-30:]
            if ultimos_30:
                promedio = sum(ultimos_30) / len(ultimos_30)
                st.sidebar.info(f"üß† Atenci√≥n √∫ltimos 30s: **{promedio:.1f}%**")
            st.session_state.last_report_time = elapsed

        time.sleep(0.03)  # Espera corta para no saturar CPU


# ---------- Resumen final ----------
# Muestra gr√°fico final y promedio cuando se detiene el monitoreo
if not st.session_state.running and st.session_state.attention_log and mostrar_tabla:
    st.subheader("üìã Resumen de atenci√≥n")
    promedio_total = sum(st.session_state.attention_log) / len(st.session_state.attention_log)
    st.markdown(f"üß† Promedio total: **{promedio_total:.2f}%**")
    fig_final = graficar_atencion(st.session_state.ventana_atencion, st.session_state.x_vals)
    st.pyplot(fig_final)

# ---------- Footer fijo ----------
st.markdown(
    """
    <style>
        .footer {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            background-color: #f9f9f9;
            color: #666;
            text-align: center;
            font-size: 0.85em;
            padding: 0.5em 0;
            border-top: 1px solid #ddd;
        }
    </style>
    <div class="footer">
        Desarrollado por <strong>Nicol√°s Bargioni</strong> | A√±o 2025 | ISSD: Inteligencia Artificial y Ciencia de Datos üß†
    </div>
    """,
    unsafe_allow_html=True
)